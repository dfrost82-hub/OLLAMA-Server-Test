---
title: Ollama + Qwen2.5 (3B) â€” Baseline
emoji: ğŸ§ 
colorFrom: blue
colorTo: green
sdk: docker
sdk_version: '1.0'
app_file: start.sh
pinned: false
license: apache-2.0
---

# ğŸ§© Ollama + Qwen2.5 (3B) â€” Baseline Space

This Space provides a minimal working setup of **Ollama** running locally inside a Hugging Face Space container and serving the **Qwen 2.5 (3B)** model through its REST API.

Itâ€™s designed as **Version 1 â€“ Baseline Validation** before extending into multimodal (VL) or image-to-video workflows.

---

## ğŸš€ What This Space Does

1. ğŸ§± Installs **Ollama** inside the container (`curl -fsSL https://ollama.com/install.sh | bash`)
2. âš™ï¸ Launches the **Ollama server** on port 11434
3. â³ Waits for the API to become ready
4. ğŸ“¥ Pulls the **Qwen 2.5 (3B)** model
5. ğŸ§ª Runs a small Python test to verify that generation works via REST API

Example log on successful startup: